{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCKitpZTpISn"
   },
   "source": [
    "# Making necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D1My5RHncNS"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "cWbZwPp6VBMi",
    "outputId": "62a2e69a-869b-4cb1-83f3-5860e803e2a2"
   },
   "outputs": [],
   "source": [
    "# NLP library imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpT3m7C2o_Qc"
   },
   "source": [
    "# Applying the transformation we've seen to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_language</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>7 novembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Le parc est tr\\u00e8s beau et bien situ\\u00e9....</td>\n",
       "      <td>fr</td>\n",
       "      <td>Parc agr\\u00e9able.</td>\n",
       "      <td>novembre 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>25 août 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Nous avons s\\u00e9journ\\u00e9 une semaine dans...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Belle d\\u00e9couverte du pays</td>\n",
       "      <td>août 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 novembre 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Rien de vraiment n\\u00e9gatif \\u00e0 part la q...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Rien \\u00e0 redire</td>\n",
       "      <td>novembre 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 septembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>C\\u00b4est un endroit calme au milieu de la fo...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Beaucoup de monde</td>\n",
       "      <td>août 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>23 avril 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Nous revenons d\\'un s\\u00e9jour en famille Le ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Bien mais pas exceptionnel</td>\n",
       "      <td>avril 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_name    published_date  rating  \\\n",
       "0  Center Parcs Het Meerdal   7 novembre 2018       3   \n",
       "1  Center Parcs Het Meerdal      25 août 2018       4   \n",
       "2  Center Parcs Het Meerdal   2 novembre 2018       4   \n",
       "3  Center Parcs Het Meerdal  2 septembre 2018       3   \n",
       "4  Center Parcs Het Meerdal     23 avril 2018       3   \n",
       "\n",
       "                                              review review_language  \\\n",
       "0  Le parc est tr\\u00e8s beau et bien situ\\u00e9....              fr   \n",
       "1  Nous avons s\\u00e9journ\\u00e9 une semaine dans...              fr   \n",
       "2  Rien de vraiment n\\u00e9gatif \\u00e0 part la q...              fr   \n",
       "3  C\\u00b4est un endroit calme au milieu de la fo...              fr   \n",
       "4  Nous revenons d\\'un s\\u00e9jour en famille Le ...              fr   \n",
       "\n",
       "                           title       trip_date  \n",
       "0            Parc agr\\u00e9able.   novembre 2018  \n",
       "1  Belle d\\u00e9couverte du pays       août 2018  \n",
       "2             Rien \\u00e0 redire   novembre 2018  \n",
       "3              Beaucoup de monde       août 2018  \n",
       "4     Bien mais pas exceptionnel      avril 2018  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json('jose_json_data.json')\n",
    "df1 = df1.drop([\"hotel_adress\",\"hotel_type\",\"image_url\",\"locid\",\"pid\",\"price_range\",\"review_id\",\"reviewer_id\",\"trip_type\"], axis = 1)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Le parc est très beau et bien situé. Les activ...\n",
       "1      Nous avons séjourné une semaine dans ce parc t...\n",
       "2      Rien de vraiment négatif à part la qualité de ...\n",
       "3      C'est un endroit calme au milieu de la forêt, ...\n",
       "4      Nous revenons d'un séjour en famille Le domain...\n",
       "5      Séjour de 5 jours pour Pâques. Nous étions au ...\n",
       "6      Merveilleux séjour à Het meerdal.La zone 4 est...\n",
       "7      Superbe séjour de 5 jours pour famille avec en...\n",
       "8      Nous avons passé 8 jours dans cet endroit. L a...\n",
       "9      Bungalow top rien a redire. Quelques soucis à ...\n",
       "10     Très beau domaine -calme - en plein nature. Le...\n",
       "11     Nous y avons séjourné pour le week end de l'as...\n",
       "12     Les cottages sont un peu vieillots et pas très...\n",
       "13     Cottage 1er prix, pas très bien nettoyé et la ...\n",
       "14     Un cottage super bien situé, sans voisin direc...\n",
       "15     j'aime absolument tout. -Cottage très propre. ...\n",
       "16     5 jours au top avec deux enfants. L'aqua Mondo...\n",
       "17     Le site très propre comme tous les center parc...\n",
       "18     Nous avons séjourné au Center Parcs Het Meerda...\n",
       "19     logement sale, humide (matelas bébé contre le ...\n",
       "20     nous avons sejourne a center parc du 13 au 18 ...\n",
       "21     cottage correct, un petit rafraichissement s'i...\n",
       "22     Excellent pour des vacances en famille. Le cot...\n",
       "23     J'aurais pu mettre la note excellente pour ce ...\n",
       "24     Semaine du 18 avril,vacances scolaires françai...\n",
       "25     Le parc en lui même est très bien, les cottage...\n",
       "26     Nous avons séjourné 8 jours dans un cottage 5 ...\n",
       "27     Nous avons passé un agréable séjour accompagné...\n",
       "28     Le parc est très chouette et très propre. Les ...\n",
       "29     Très  bien  avec  des enfants.  Beaucoup  d'ac...\n",
       "                             ...                        \n",
       "134    Bungalow pas mieux en état. Il est très diffic...\n",
       "135    Nous avons séjourné dans cet hôtel pendant une...\n",
       "136    L'endroit est agréable. Le personnel est très ...\n",
       "137    Il nous a fallu assez longtemps pour trouver l...\n",
       "138    Nous sommes allés dans notre petit garçon qui ...\n",
       "139    Le Dôme et son Aqua Mundo étaient parfaitement...\n",
       "140    Une fois de plus, nous avons passé d'excellent...\n",
       "141    Nous avons passé un très bon moment à Het Meer...\n",
       "142    Nous avons réservé un cottage confortable avec...\n",
       "143    Nous venons de rentrer d'un séjour de 3 jours ...\n",
       "144    Les cottages sont très confortables et bien en...\n",
       "145    Het Meerdal était un endroit merveilleux à vis...\n",
       "146    Très bon rapport qualité prix - super pour une...\n",
       "147    J'ai séjourné pour une pause en plein milieu d...\n",
       "148    Nous avons apprécié le parc aquatique ! Cet en...\n",
       "149    Nous y avons séjourné avec ma famille et mes a...\n",
       "150    Cet endroit très incroyable pour les jeunes ge...\n",
       "151    Je recommande Het Meerdal. C'est un très bon s...\n",
       "152    Nous avons eu une autre super vacances à Het M...\n",
       "153    Un séjour très agréable et reposant dans une t...\n",
       "154    Très satisfaits de notre confort pas réaménage...\n",
       "155    Nous ne savions pas à quoi nous attendre, mais...\n",
       "156    Un peu plus petite et plus calme que les homol...\n",
       "157    Quel endroit merveilleux avec un enfant ! Nous...\n",
       "158    Nous allons à Center Parcs pendant des années....\n",
       "159    Nous avons visité le parc avec 3 autres famill...\n",
       "160    Ce parc est vraiment calme et relaxant, bon d'...\n",
       "161    C'est la deuxième fois que nous avons visité H...\n",
       "162    Notre premier séjour à Center Parcs et n'ai pa...\n",
       "163    En termes de rapport qualité/prix dans l'ensem...\n",
       "Name: review, Length: 164, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.review = df1.review.apply(lambda x:x.replace(r\"\\u00e8\",\"è\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00e9', 'é'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r\"\\u00ea\",\"ê\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r\"\\u00eb\",\"ë\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r\"\\u00fb\",\"û\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r\"\\u00f9\",\"ù\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00e0', 'à'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00e2', 'â'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00f4', 'ô'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00ee', 'î'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00ef', 'ï'))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u2019', \"'\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\'', \"'\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r' u00b4', \"'\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00b4', \"'\"))\n",
    "df1.review = df1.review.apply(lambda x:x.replace(r'\\u00e7', \"ç\"))\n",
    "\n",
    "df1.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         Parc agréable.\n",
       "1                               Belle découverte du pays\n",
       "2                                          Rien à redire\n",
       "3                                      Beaucoup de monde\n",
       "4                             Bien mais pas exceptionnel\n",
       "5                                   repos et dépaysement\n",
       "6                                    Vacances de pâques \n",
       "7                         Super séjour spécial famille! \n",
       "8                  il faut parler anglais ou néerlandais\n",
       "9                                               Mitigée \n",
       "10                                     Très beau domaine\n",
       "11     Séjour très agréable qui a ravi enfants-parent...\n",
       "12                                     Beau dépaysemment\n",
       "13            Séjour agréable pour toute les générations\n",
       "14              Une escapade en famille sous le soleil !\n",
       "15                         Très contents de notre séjour\n",
       "16                                    Vacances de Pâques\n",
       "17                                  Bien mais sans plus \n",
       "18      Parc et Aqua mundo au top mais cottage archaïque\n",
       "19                               logement humide et sale\n",
       "20                                                 super\n",
       "21                                                 SUPER\n",
       "22                                             Très bien\n",
       "23            Trés bien mais déçu par un des restaurants\n",
       "24                                                  Bien\n",
       "25        Déçus par la présence de voitures dans le parc\n",
       "26                                    séjours de 8 jours\n",
       "27                                      Très bon séjour \n",
       "28                                         Très chouette\n",
       "29                                Bon séjour  en famille\n",
       "                             ...                        \n",
       "134                  Un bel endroit. Mauvais restaurant.\n",
       "135    Très pratique et agréable endroit pour des vac...\n",
       "136               Un séjour agréable, pour les enfants !\n",
       "137                           Préparez-vous à être perdu\n",
       "138                                          Parc démodé\n",
       "139      Aqua Mundo fantastique, bungalows très vieillot\n",
       "140          Elle Meerdal - un super week-end en famille\n",
       "141                          Super Center Parcs vacances\n",
       "142                                Très sale cottage !!!\n",
       "143    Ok , si ça vous est égal à votre lieu d'héberg...\n",
       "144                 Vacances ta Center Parcs Het Meerdal\n",
       "145                          Une visite exceptionnelle !\n",
       "146           Vraiment un excellent rapport qualité/prix\n",
       "147                    Super break, piscines excellentes\n",
       "148                             Center Parc, Het Meerdal\n",
       "149                                        Long week-end\n",
       "150               Un super endroit pour les jeunes gens.\n",
       "151                     Notre 1 er voyage en Het Meerdal\n",
       "152                Un autre heureux séjour à Het Meerdal\n",
       "153                                         Un Fun Break\n",
       "154                               A dépassé nos attentes\n",
       "155                                         Super séjour\n",
       "156                                           Relaxant !\n",
       "157                        Het Meerdal - Majestic séjour\n",
       "158                                  Vacances en famille\n",
       "159    Nous avons passé un très bon moment. Mes enfan...\n",
       "160              Profitez et détendez-vous dans ce parc.\n",
       "161                            Bonne vacances en famille\n",
       "162                        Premier voyage à Center Parcs\n",
       "163                         Durée de demi-in Het Meerdal\n",
       "Name: title, Length: 164, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.title = df1.title.apply(lambda x:x.replace(r\"\\u00e8\",\"è\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00e9', 'é'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r\"\\u00ea\",\"ê\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r\"\\u00eb\",\"ë\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r\"\\u00f9\",\"ù\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00ee', 'î'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00ef', 'ï'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r\"\\u00fb\",\"û\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00e0', 'à'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00e2', 'â'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00f4', 'ô'))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00e7', \"ç\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u2019', \"'\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\'', \"'\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r' u00b4', \"'\"))\n",
    "df1.title = df1.title.apply(lambda x:x.replace(r'\\u00b4', \"'\"))\n",
    "\n",
    "df1.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r\"\\u00e8\",\"è\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00e9', 'é'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r\"\\u00ea\",\"ê\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r\"\\u00eb\",\"ë\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r\"\\u00f9\",\"ù\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00ee', 'î'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00ef', 'ï'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r\"\\u00fb\",\"û\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00e0', 'à'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00e2', 'â'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00f4', 'ô'))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u2019', \"'\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\'', \"'\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r' u00b4e', \"'\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r' u00b4', \"'\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00b4', \"'\"))\n",
    "df1.trip_date = df1.trip_date.apply(lambda x:x.replace(r'\\u00e7', \"ç\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_language</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>7 novembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Le parc est très beau et bien situé. Les activ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Parc agréable.</td>\n",
       "      <td>novembre 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>25 août 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Nous avons séjourné une semaine dans ce parc t...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Belle découverte du pays</td>\n",
       "      <td>août 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 novembre 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Rien de vraiment négatif à part la qualité de ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Rien à redire</td>\n",
       "      <td>novembre 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 septembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>C'est un endroit calme au milieu de la forêt, ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Beaucoup de monde</td>\n",
       "      <td>août 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>23 avril 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Nous revenons d'un séjour en famille Le domain...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Bien mais pas exceptionnel</td>\n",
       "      <td>avril 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_name    published_date  rating  \\\n",
       "0  Center Parcs Het Meerdal   7 novembre 2018       3   \n",
       "1  Center Parcs Het Meerdal      25 août 2018       4   \n",
       "2  Center Parcs Het Meerdal   2 novembre 2018       4   \n",
       "3  Center Parcs Het Meerdal  2 septembre 2018       3   \n",
       "4  Center Parcs Het Meerdal     23 avril 2018       3   \n",
       "\n",
       "                                              review review_language  \\\n",
       "0  Le parc est très beau et bien situé. Les activ...              fr   \n",
       "1  Nous avons séjourné une semaine dans ce parc t...              fr   \n",
       "2  Rien de vraiment négatif à part la qualité de ...              fr   \n",
       "3  C'est un endroit calme au milieu de la forêt, ...              fr   \n",
       "4  Nous revenons d'un séjour en famille Le domain...              fr   \n",
       "\n",
       "                        title       trip_date  \n",
       "0              Parc agréable.   novembre 2018  \n",
       "1    Belle découverte du pays       août 2018  \n",
       "2               Rien à redire   novembre 2018  \n",
       "3           Beaucoup de monde       août 2018  \n",
       "4  Bien mais pas exceptionnel      avril 2018  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemming/Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "V-Lu49mLnke7",
    "outputId": "d5ced2c8-3d38-4309-d0ce-c9bd43d95931"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_language</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>18 novembre 2013</td>\n",
       "      <td>4</td>\n",
       "      <td>Nous avons visité le parc avec 3 autres famill...</td>\n",
       "      <td>en</td>\n",
       "      <td>Nous avons passé un très bon moment. Mes enfan...</td>\n",
       "      <td>novembre 2013</td>\n",
       "      <td>[visite, familles, enfants, o 15, restes, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>20 janvier 2012</td>\n",
       "      <td>4</td>\n",
       "      <td>Ce parc est vraiment calme et relaxant, bon d'...</td>\n",
       "      <td>en</td>\n",
       "      <td>Profitez et détendez-vous dans ce parc.</td>\n",
       "      <td>janvier 2012</td>\n",
       "      <td>[calme, relaxant, bon, d avoir, famille, proch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>17 janvier 2012</td>\n",
       "      <td>4</td>\n",
       "      <td>C'est la deuxième fois que nous avons visité H...</td>\n",
       "      <td>en</td>\n",
       "      <td>Bonne vacances en famille</td>\n",
       "      <td>janvier 2012</td>\n",
       "      <td>[deuxieme, visite, het, meerdal, premiers, vil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>1 novembre 2013</td>\n",
       "      <td>4</td>\n",
       "      <td>Notre premier séjour à Center Parcs et n'ai pa...</td>\n",
       "      <td>en</td>\n",
       "      <td>Premier voyage à Center Parcs</td>\n",
       "      <td>octobre 2013</td>\n",
       "      <td>[premier, n ai, decu, super, enfants, superbes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>5 novembre 2012</td>\n",
       "      <td>5</td>\n",
       "      <td>En termes de rapport qualité/prix dans l'ensem...</td>\n",
       "      <td>en</td>\n",
       "      <td>Durée de demi-in Het Meerdal</td>\n",
       "      <td>octobre 2012</td>\n",
       "      <td>[termes, qualite prix, l ensemble, redire, het...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hotel_name    published_date  rating  \\\n",
       "159  Center Parcs Het Meerdal  18 novembre 2013       4   \n",
       "160  Center Parcs Het Meerdal   20 janvier 2012       4   \n",
       "161  Center Parcs Het Meerdal   17 janvier 2012       4   \n",
       "162  Center Parcs Het Meerdal   1 novembre 2013       4   \n",
       "163  Center Parcs Het Meerdal   5 novembre 2012       5   \n",
       "\n",
       "                                                review review_language  \\\n",
       "159  Nous avons visité le parc avec 3 autres famill...              en   \n",
       "160  Ce parc est vraiment calme et relaxant, bon d'...              en   \n",
       "161  C'est la deuxième fois que nous avons visité H...              en   \n",
       "162  Notre premier séjour à Center Parcs et n'ai pa...              en   \n",
       "163  En termes de rapport qualité/prix dans l'ensem...              en   \n",
       "\n",
       "                                                 title       trip_date  \\\n",
       "159  Nous avons passé un très bon moment. Mes enfan...   novembre 2013   \n",
       "160            Profitez et détendez-vous dans ce parc.    janvier 2012   \n",
       "161                          Bonne vacances en famille    janvier 2012   \n",
       "162                      Premier voyage à Center Parcs    octobre 2013   \n",
       "163                       Durée de demi-in Het Meerdal    octobre 2012   \n",
       "\n",
       "                                                tokens  \n",
       "159  [visite, familles, enfants, o 15, restes, pass...  \n",
       "160  [calme, relaxant, bon, d avoir, famille, proch...  \n",
       "161  [deuxieme, visite, het, meerdal, premiers, vil...  \n",
       "162  [premier, n ai, decu, super, enfants, superbes...  \n",
       "163  [termes, qualite prix, l ensemble, redire, het...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing transformations for preprocessing function\n",
    "caracters_to_remove = list(string.punctuation)\n",
    "transformation_car_dict = {initial:\" \" for initial in caracters_to_remove}\n",
    "\n",
    "with_accent = ['é', 'è', 'ê', 'à', 'ù', 'ç', 'ô', 'î']\n",
    "without_accent = ['e', 'e', 'e', 'a', 'u', 'c', 'o', 'i']\n",
    "transformation_accent_dict = {before:after for before, after in zip(with_accent, without_accent)}\n",
    "\n",
    "stopW = stopwords.words('french')\n",
    "stopW += ['les', 'a', 'tout'\"good\", \"great\", \"one\", \"nt\", \"u2013\", \"\", \"would\", \"get\", \"center\", \"parcs\",\"the\",\"le\"\n",
    "                   ,\" u00e0\",\"nous\",\"with\",\"what\",\"for\",\"etait\",\"not\",\"the\",\"une\",\"de\",\"pour\",\"plus\",\"zip\",\"under\",\"but\",\"tr u00e0\",\"   \",\n",
    "                  'n\\'t','...','\\'ve','\\'re', 'ã\\x9dou', \"''\", 'avez','est','être','être.on','le','les','de','et','la','pour','très','à',\n",
    "                'en','a','des','pas','dans','du','au','avec','sont','que','avons','de','et','pour'\n",
    "                ,'nous','un','est','en','des','pas','dans','du','au','avec','-\\\\taqua','-\\\\ten','-\\\\tle','farfelues.moi','\\\\u2764','amp','dis','\\\\u00bc',\n",
    "               'tré','tres','-\\\\tpas','-\\\\tla','1m01','cafetière\\\\u2026','une','tout','mais','qui','il','sur',\"c'est\",'ne','plus','ce','se',\n",
    "               'aux','je','peu','vraiment','par','vous','fait','faire','était','car','ou','quot','si','sans','tous','aussi','fois','n','ans','entre','peut',\n",
    "               'semaine','faut','voir','3','eu','cela','ont','nos','4','même','nos','contre','donc','surtour','son','reste','séjour','site','rapport',\n",
    "                'surtout','quand','2','sommes','sinon','vu','jours','assez','autres','\\u00e7a','ménage',\"n'est\",'toujours','soit','c','l','malgré','comme',\n",
    "                'niveau','toutes','non','avions','toute','\\u00e7a','mon','moins','passer','devant','où',\"c est\",\"trop\",\" u00e7a\",\"parc\",\"daims\",\"cottage\",\n",
    "                   \"sejour\",\"etre\",\"mundo\",\"rien\",'aqua',\"bois\",\"cottages\",\"passe\",\"l aqua\",\"d activites\",\"n'est\",\"j'ai\",'avant','apres','ils','alors',\n",
    "                   'trouve','deja',\"qu il\",'dit']\n",
    "\n",
    "\n",
    "# Preprocessing function to apply to the content column\n",
    "def preprocessing(review):\n",
    "  \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(review)\n",
    "    \n",
    "    # Deleting words with  only one caracter\n",
    "    tokens = [token for token in tokens if len(token)>2]\n",
    "    \n",
    "    # stopwords + lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopW]   \n",
    "    \n",
    "    # Removing accents\n",
    "    tokens = [token.translate(str.maketrans(transformation_accent_dict)) for token in tokens]\n",
    "    \n",
    "    # Deleting specific caracters\n",
    "    tokens = [token.translate(str.maketrans(transformation_car_dict)) for token in tokens]\n",
    "        \n",
    "    return tokens\n",
    "  \n",
    "\n",
    "# Creating a new column swith tokenized reviews\n",
    "df1['tokens'] = df1['review'].apply(preprocessing)\n",
    "\n",
    "# Displaying part of the result\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-WARsCeo-JL"
   },
   "source": [
    "# Discovering [Stemming](https://en.wikipedia.org/wiki/Stemming) and [Lemmatisation](https://en.wikipedia.org/wiki/Lemmatisation)\n",
    "\n",
    "\n",
    "If you want to understand how the [Porter Algorithm](https://fr.wikipedia.org/wiki/Racinisation#Algorithme_de_Porter) works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Stemmer objects\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-2VUwd4kKL2"
   },
   "source": [
    "## Visualizing the effects of two different stemmers on basic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EHK8XvxD3v_G",
    "outputId": "83c80b3a-2efa-4860-b12e-4bb9119d8b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMc4hDBnkT8n"
   },
   "source": [
    "## Effects on a total sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zVE0VoS4Pp9"
   },
   "outputs": [],
   "source": [
    "def stemSentence(sentence, stemmer):\n",
    "    \n",
    "    token_words = word_tokenize(sentence)\n",
    "    stem_sentence = []\n",
    "    \n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    \n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FZsE-n21lxwN",
    "outputId": "b98b81ae-f78e-4fcb-f355-5869d5e4c1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ar very intellig and work very python and now they ar python their way to success . \n",
      "python are veri intellig and work veri pythonli and now they are python their way to success . \n"
     ]
    }
   ],
   "source": [
    "# And compare differences\n",
    "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
    "\n",
    "print(stemSentence(sentence, lancaster))\n",
    "print(stemSentence(sentence, porter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Qcbb5PYKlzCD",
    "outputId": "ec9de27e-88be-4900-e74d-038a1e6dfd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce matin je sui allé achet un galet à la boulangery pui je me sui régalé av de venir en cour . \n",
      "Ce matin je sui allé achet une galett à la boulangeri pui je me sui régalé avant de venir en cour . \n"
     ]
    }
   ],
   "source": [
    "# Look at what is happening on a french sentence\n",
    "sentence=\"Ce matin je suis allé acheter une galette à la boulangerie puis je me suis régalé avant de venir en cours.\"\n",
    "\n",
    "print(stemSentence(sentence, lancaster))\n",
    "print(stemSentence(sentence, porter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxILJkRnkeZ2"
   },
   "source": [
    "## A stemmer to use on different languages (for example french..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iMi9p7VH4Rbx",
    "outputId": "7a5d169f-762b-481c-931f-840bcba2895b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cet phras est à la fois amus et surpren '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frenchStemSentence(sentence):\n",
    "    frenchStemmer=SnowballStemmer(\"french\", ignore_stopwords=False)\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(frenchStemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "frenchStemSentence(\"cette phrase est à la fois amusante et surprenante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELSBOPDTorCM"
   },
   "source": [
    "## Having a look at lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y3nNOH9FWpM8",
    "outputId": "d52954c5-07b4-4e07-b46e-857ee852db7e"
   },
   "outputs": [],
   "source": [
    "# Initiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create lematizing function\n",
    "def lemmatize(sentence):\n",
    "    tokens=word_tokenize(sentence)\n",
    "    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(token,pos='a'),pos='v'),pos='n') for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# And display results\n",
    "lemmer = lemmatize(\"Such an analysis can reveal features that are not easily visible from the variations in the individual genes and can lead to a picture of expression that is more biologically transparent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Such an analysis can reveal feature that be not easily visible from the variation in the individual gene and can lead to a picture of expression that be more biologically transparent'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUN-NholwS3a"
   },
   "source": [
    "# Applying one of those modification to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VP7Tn1Uy4tj"
   },
   "source": [
    " **Preparing both functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14FnlWXwoum9"
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(token,pos='a'),pos='v'),pos='n') for token in tokens]\n",
    "    return tokens  \n",
    "\n",
    "# Stemming\n",
    "frenchStemmer=SnowballStemmer(\"french\")\n",
    "def stem(tokens):\n",
    "    tokens = [frenchStemmer.stem(token) for token in tokens]\n",
    "    return tokens  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZHHZdbjzBlI"
   },
   "source": [
    "**Selecting which one to apply, given the language used in your reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZIv9DttzLml"
   },
   "outputs": [],
   "source": [
    "# Are your reviews in English ? (here it is unfortunately not the case)\n",
    "english = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9VkIu1_zO2Z"
   },
   "source": [
    "**And finally applying it to our dataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "3QRw4_nLySif",
    "outputId": "c2bd7108-eb38-4b0a-b388-92eeef98393e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_language</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>Lemmatisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>7 novembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Le parc est très beau et bien situé. Les activ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Parc agréable.</td>\n",
       "      <td>novembre 2018</td>\n",
       "      <td>[beau, bien, situe, activites, variees, parfoi...</td>\n",
       "      <td>[beau, bien, situ, activit, varie, parfois, ch...</td>\n",
       "      <td>[beau, bien, situe, activites, variees, parfoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>25 août 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Nous avons séjourné une semaine dans ce parc t...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Belle découverte du pays</td>\n",
       "      <td>août 2018</td>\n",
       "      <td>[sejourne, agreable, bien, entretenu l aqua, g...</td>\n",
       "      <td>[sejourn, agreabl, bien, entretenu l aqu, gran...</td>\n",
       "      <td>[sejourne, agreable, bien, entretenu l aqua, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 novembre 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Rien de vraiment négatif à part la qualité de ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Rien à redire</td>\n",
       "      <td>novembre 2018</td>\n",
       "      <td>[negatif, part, qualite, literie, matelas, mou...</td>\n",
       "      <td>[negat, part, qualit, liter, matel, mou, manqu...</td>\n",
       "      <td>[negatif, part, qualite, literie, matelas, mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>2 septembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>C'est un endroit calme au milieu de la forêt, ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Beaucoup de monde</td>\n",
       "      <td>août 2018</td>\n",
       "      <td>[endroit, calme, milieu, foret, grand, bien, e...</td>\n",
       "      <td>[endroit, calm, milieu, foret, grand, bien, en...</td>\n",
       "      <td>[endroit, calme, milieu, foret, grand, bien, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Center Parcs Het Meerdal</td>\n",
       "      <td>23 avril 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Nous revenons d'un séjour en famille Le domain...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Bien mais pas exceptionnel</td>\n",
       "      <td>avril 2018</td>\n",
       "      <td>[revenons, d un, famille, domaine, propre, ent...</td>\n",
       "      <td>[revenon, d un, famill, domain, propr, entrete...</td>\n",
       "      <td>[revenons, d un, famille, domaine, propre, ent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_name    published_date  rating  \\\n",
       "0  Center Parcs Het Meerdal   7 novembre 2018       3   \n",
       "1  Center Parcs Het Meerdal      25 août 2018       4   \n",
       "2  Center Parcs Het Meerdal   2 novembre 2018       4   \n",
       "3  Center Parcs Het Meerdal  2 septembre 2018       3   \n",
       "4  Center Parcs Het Meerdal     23 avril 2018       3   \n",
       "\n",
       "                                              review review_language  \\\n",
       "0  Le parc est très beau et bien situé. Les activ...              fr   \n",
       "1  Nous avons séjourné une semaine dans ce parc t...              fr   \n",
       "2  Rien de vraiment négatif à part la qualité de ...              fr   \n",
       "3  C'est un endroit calme au milieu de la forêt, ...              fr   \n",
       "4  Nous revenons d'un séjour en famille Le domain...              fr   \n",
       "\n",
       "                        title       trip_date  \\\n",
       "0              Parc agréable.   novembre 2018   \n",
       "1    Belle découverte du pays       août 2018   \n",
       "2               Rien à redire   novembre 2018   \n",
       "3           Beaucoup de monde       août 2018   \n",
       "4  Bien mais pas exceptionnel      avril 2018   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [beau, bien, situe, activites, variees, parfoi...   \n",
       "1  [sejourne, agreable, bien, entretenu l aqua, g...   \n",
       "2  [negatif, part, qualite, literie, matelas, mou...   \n",
       "3  [endroit, calme, milieu, foret, grand, bien, e...   \n",
       "4  [revenons, d un, famille, domaine, propre, ent...   \n",
       "\n",
       "                                            Stemming  \\\n",
       "0  [beau, bien, situ, activit, varie, parfois, ch...   \n",
       "1  [sejourn, agreabl, bien, entretenu l aqu, gran...   \n",
       "2  [negat, part, qualit, liter, matel, mou, manqu...   \n",
       "3  [endroit, calm, milieu, foret, grand, bien, en...   \n",
       "4  [revenon, d un, famill, domain, propr, entrete...   \n",
       "\n",
       "                                       Lemmatisation  \n",
       "0  [beau, bien, situe, activites, variees, parfoi...  \n",
       "1  [sejourne, agreable, bien, entretenu l aqua, g...  \n",
       "2  [negatif, part, qualite, literie, matelas, mou...  \n",
       "3  [endroit, calme, milieu, foret, grand, bien, e...  \n",
       "4  [revenons, d un, famille, domaine, propre, ent...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making appropriate modification\n",
    "df1['Stemming'] = df1['tokens'].apply(stem)\n",
    "\n",
    "df1['Lemmatisation'] = df1['tokens'].apply(lemmatize)\n",
    "\n",
    "# And displaying results\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('clean_data_jose.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['beau', 'bien', 'situe', 'activites', 'variee...\n",
       "1      ['sejourne', 'agreable', 'bien', 'entretenu l ...\n",
       "2      ['negatif', 'part', 'qualite', 'literie', 'mat...\n",
       "3      ['endroit', 'calme', 'milieu', 'foret', 'grand...\n",
       "4      ['revenons', 'd un', 'famille', 'domaine', 'pr...\n",
       "5      ['pâques', 'numero', '536', 'proche', 'lac', '...\n",
       "6      ['merveilleux', 'het', 'meerdal la', 'zone', '...\n",
       "7      ['superbe', 'famille', 'enfants', 'jeunes', 'g...\n",
       "8      ['passe', 'cet', 'endroit', 'bien', 'petit', '...\n",
       "9      ['bungalow', 'top', 'redire', 'quelques', 'sou...\n",
       "10     ['beau', 'domaine', ' calme', 'plein', 'nature...\n",
       "11     ['sejourne', 'week', 'end', 'l ascension', 'te...\n",
       "12     ['vieillots', 'bien', 'equipes', 'four', 'lave...\n",
       "13     ['1er', 'prix', 'bien', 'nettoye', 'literie', ...\n",
       "14     ['super', 'bien', 'situe', 'voisin', 'direct',...\n",
       "15     ['j aime', 'absolument', ' cottage', 'propre',...\n",
       "16     ['top', 'deux', 'enfants', 'l aqua', 'mondo', ...\n",
       "17     ['propre', 'terrible', 'cour', 'dome', 'commer...\n",
       "18     ['sejourne', 'het', 'meerdal', 'juillet', '201...\n",
       "19     ['logement', 'sale', 'humide', 'matelas', 'beb...\n",
       "20     ['sejourne', 'fevrier', '2017', 'points', 'pos...\n",
       "21     ['correct', 'petit', 'rafraichissement', 's im...\n",
       "22     ['excellent', 'vacances', 'famille', 'excellen...\n",
       "23     ['j aurais', 'mettre', 'note', 'excellente', '...\n",
       "24     ['avril', 'vacances', 'scolaires', 'francaises...\n",
       "25     ['bien', 'egalement', 'fortement', 'decus', 'g...\n",
       "26     ['sejourne', 'personnes', 'premium', '770', 's...\n",
       "27     ['passe', 'agreable', 'accompagne', 'enfants',...\n",
       "28     ['chouette', 'propre', 'promenades', 'velo', '...\n",
       "29     ['bien', 'enfants', 'beaucoup', 'd activites',...\n",
       "                             ...                        \n",
       "134    ['bungalow', 'mieux', 'etat', 'difficile', 'ou...\n",
       "135    ['sejourne', 'cet', 'hotel', 'pendant', 'deux'...\n",
       "136    ['l endroit', 'agreable', 'personnel', 'sympa'...\n",
       "137    ['fallu', 'longtemps', 'trouver', 'l entree', ...\n",
       "138    ['alles', 'petit', 'garcon', 'loue', 'maison',...\n",
       "139    ['dome', 'parfaitement', 'entretenus', 'bungal...\n",
       "140    ['passe', 'd excellentes', 'vacances', 'famill...\n",
       "141    ['passe', 'bon', 'moment', 'het', 'meerdal', '...\n",
       "142    ['reserve', 'confortable', 'enfants', 'arrives...\n",
       "143    ['venons', 'rentrer', 'd un', 'cet', 'hotel', ...\n",
       "144    ['confortables', 'bien', 'entretenu', 'personn...\n",
       "145    ['het', 'meerdal', 'endroit', 'merveilleux', '...\n",
       "146    ['bon', 'qualite', 'prix', 'super', 'jeune', '...\n",
       "147    ['sejourne', 'pause', 'plein', 'milieu', 'août...\n",
       "148    ['apprecie', 'aquatique', 'cet', 'endroit', 'p...\n",
       "149    ['sejourne', 'famille', 'amis', 'trouve', 'per...\n",
       "150    ['cet', 'endroit', 'incroyable', 'jeunes', 'ge...\n",
       "151    ['recommande', 'het', 'meerdal', 'bon', 'plein...\n",
       "152    ['autre', 'super', 'vacances', 'het', 'meerdal...\n",
       "153    ['agreable', 'reposant', 'belle', 'partie', 'h...\n",
       "154    ['satisfaits', 'confort', 'reamenagements', 'l...\n",
       "155    ['savions', 'quoi', 'attendre', 'agreablement'...\n",
       "156    ['petite', 'calme', 'homologues', 'anglais', '...\n",
       "157    ['quel', 'endroit', 'merveilleux', 'enfant', '...\n",
       "158    ['allons', 'pendant', 'annees', 'cette', 'anne...\n",
       "159    ['visite', 'familles', 'enfants', 'o 15', 'res...\n",
       "160    ['calme', 'relaxant', 'bon', 'd avoir', 'famil...\n",
       "161    ['deuxieme', 'visite', 'het', 'meerdal', 'prem...\n",
       "162    ['premier', 'n ai', 'decu', 'super', 'enfants'...\n",
       "163    ['termes', 'qualite prix', 'l ensemble', 'redi...\n",
       "Name: tokens, Length: 164, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai2 = pd.read_csv('clean_data_jose.csv')\n",
    "\n",
    "essai2.head()\n",
    "\n",
    "essai2['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6faNnlpH3L8-"
   },
   "source": [
    "# Final modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "wsQgbDCUpSGG",
    "outputId": "7b238486-e3c6-468c-98d5-d2c693e723b5"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-13eb23d8937a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Why not doing the same on title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Finally keeping only necessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-095b5c29c872>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Deleting words with  only one caracter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     return [\n\u001b[1;32m    145\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m    104\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \"\"\"\n\u001b[0;32m-> 1269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \"\"\"\n\u001b[0;32m-> 1323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \"\"\"\n\u001b[0;32m-> 1323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \"\"\"\n\u001b[1;32m   1353\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Why not doing the same on title \n",
    "df['title'] = df['title'].apply(preprocessing).apply(stem)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Finally keeping only necessary columns\n",
    "del(df['review'])\n",
    "del(df['tokens'])\n",
    "\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "X_HEC_Session_3_Notebook_2_stemming.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
