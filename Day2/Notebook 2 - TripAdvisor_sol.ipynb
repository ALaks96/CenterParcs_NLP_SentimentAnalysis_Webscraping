{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Science for Business - Data Science Consulting - Session 2 \n",
    "\n",
    "# Notebook 2: \n",
    "\n",
    "# Web Scraping with Scrapy: Getting reviews from TripAdvisor\n",
    "\n",
    "To Do (note for Cap): <br>\n",
    "-Enlever des parties du code que les élèves doivent compléter par eux même "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "import sys\n",
    "from scrapy.http import Request\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# https://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "class HotelreviewsItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    rating = scrapy.Field()\n",
    "    review = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    trip_date = scrapy.Field()\n",
    "    trip_type = scrapy.Field()\n",
    "    published_date = scrapy.Field()\n",
    "    hotel_type = scrapy.Field()\n",
    "    hotel_name = scrapy.Field()\n",
    "    price_range = scrapy.Field()\n",
    "    reviewer_id = scrapy.Field()\n",
    "    review_language = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info_splitter(raw_user_info):\n",
    "    \"\"\"\n",
    "\n",
    "    :param raw_user_info:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    user_info = {}\n",
    "\n",
    "    splited_info = raw_user_info.split()\n",
    "    for element in splited_info:\n",
    "        converted_element = get_convertible_elements_as_dic(element)\n",
    "        if converted_element:\n",
    "            user_info[converted_element[0]] = converted_element[1]\n",
    "\n",
    "    return user_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the JSon pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSon pipeline, you can rename the \"trust.jl\" to the name of your choice\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('tripadvisor.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spider\n",
    "\n",
    "When you go on a TripAdvisor page, you will have 5 reviews per page. Reviews are not fully displayed on the page, so you have to open them (i.e follow the link of the review to tell Scrapy to scrape this page) to scrape them. <br>\n",
    "This means we will use 2 parsing functions: <br>\n",
    "-The first one will go on the page of the parc, and get the links of the reviews <br>\n",
    "-The second one will go on each page of each reviews and scrape them using the parse_item() method. <br>\n",
    "\n",
    "<b>To Do</b>: Complete the code with XPath to get the proper item to scrape. Once you are done, you can \"Restart and run all cells\" to see if everything is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpider(CrawlSpider):\n",
    "    name = 'BasicSpider'\n",
    "    domain_url = \"https://www.tripadvisor.com\"\n",
    "    # allowed_domains = [\"https://www.tripadvisor.com\"]\n",
    "\n",
    "    start_urls = [\n",
    "        \"https://www.tripadvisor.fr/ShowUserReviews-g1573379-d1573383-r629218790-Center_Parcs_Les_Trois_Forets-Hattigny_Moselle_Grand_Est.html\",\n",
    "    \"https://www.tripadvisor.fr/ShowUserReviews-g1573379-d1573383-r645720538-Center_Parcs_Les_Trois_Forets-Hattigny_Moselle_Grand_Est.html\"]\n",
    "    \n",
    "        #Custom settings to modify settings usually found in the settings.py file \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'tripadvisor.json'                        # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        item = HotelreviewsItem()\n",
    "\n",
    "        item[\"reviewer_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-memberid\").extract()),\n",
    "                                   None)\n",
    "        item[\"review_language\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-language\").extract()),\n",
    "                                       None)\n",
    "\n",
    "        review_url_on_page = response.xpath('//script[@type=\"application/ld+json\"]/text()').extract()\n",
    "        review = eval(review_url_on_page[0])\n",
    "\n",
    "        item[\"review\"] = review[\"reviewBody\"].replace(\"\\\\n\", \"\")\n",
    "        item[\"title\"] = review[\"name\"]\n",
    "        item[\"rating\"] = review[\"reviewRating\"][\"ratingValue\"]\n",
    "        item[\"hotel_type\"] = review[\"itemReviewed\"][\"@type\"]\n",
    "        item[\"hotel_name\"] = review[\"itemReviewed\"][\"name\"]\n",
    "        item[\"price_range\"] = review[\"itemReviewed\"][\"priceRange\"]\n",
    "        try:\n",
    "            item[\"published_date\"] = review[\"datePublished\"]\n",
    "        except KeyError:\n",
    "\n",
    "            item[\"published_date\"] = next(iter(response.xpath(\n",
    "                f\"//div[contains(@id,'review_{review_id}')]/div/div/span[@class='ratingDate']/@title\"\"\").extract()),\n",
    "                                          None)\n",
    "\n",
    "        item[\"trip_type\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                     \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div\"\n",
    "                                                     \"/div/div/div[contains(@class,'noRatings')]/text()\").extract()),\n",
    "                                 None)\n",
    "\n",
    "        try:\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                         \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div[\"\n",
    "                                                         \"contains(@class,'prw_reviews_stay_date_hsx')]/text()\").extract(\n",
    "\n",
    "            )), None)\n",
    "\n",
    "        except:\n",
    "\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\n",
    "                \"//div[contains(@id,'review_538163624')]/div/div/div[@data-prwidget-name='reviews_stay_date_hsx']/text()\").extract()),\n",
    "                                     None)\n",
    "\n",
    "        yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-21 19:32:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2019-01-21 19:32:02 [scrapy.utils.log] INFO: Versions: lxml 4.3.0.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.4.2, Platform Darwin-15.6.0-x86_64-i386-64bit\n",
      "2019-01-21 19:32:02 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'tripadvisor.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    },
    {
     "ename": "ReactorNotRestartable",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReactorNotRestartable\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d7c6e467c68a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMySpider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scrapy/crawler.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, stop_after_crawl)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjustPoolsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REACTOR_THREADPOOL_MAXSIZE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSystemEventTrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shutdown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_dns_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \"\"\"\n\u001b[1;32m   1221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_installSignalHandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mReactorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorAlreadyRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_startedBefore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorNotRestartable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReactorNotRestartable\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importing and reading data scraped\n",
    "\n",
    "If you've succeeded, you should see here a dataframe with 2 entries corresponding to the 2 first reviews of the parc, and 11 columns for each item scraped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>hotel_type</th>\n",
       "      <th>price_range</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_language</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center Parcs - Les Trois Forêts</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>82€ - 246€  (Selon les tarifs moyens d'une cha...</td>\n",
       "      <td>14 janvier 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>c\\'est le troisi\\u00e8me center parc qu\\'on vi...</td>\n",
       "      <td>fr</td>\n",
       "      <td>&lt;div&gt;Sightsee26280840290&lt;/div&gt;</td>\n",
       "      <td>logement tout equip\\u00e9, luxury</td>\n",
       "      <td>janvier 2019</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Center Parcs - Les Trois Forêts</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>82€ - 246€  (Selon les tarifs moyens d'une cha...</td>\n",
       "      <td>28 octobre 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Seconde fois que nous venons au Center Parcs d...</td>\n",
       "      <td>fr</td>\n",
       "      <td>&lt;div&gt;Kathys25&lt;/div&gt;</td>\n",
       "      <td>D\\u00e9paysant!</td>\n",
       "      <td>septembre 2018</td>\n",
       "      <td>A voyagé en famille</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hotel_name       hotel_type  \\\n",
       "0  Center Parcs - Les Trois Forêts  LodgingBusiness   \n",
       "1  Center Parcs - Les Trois Forêts  LodgingBusiness   \n",
       "\n",
       "                                         price_range   published_date  rating  \\\n",
       "0  82€ - 246€  (Selon les tarifs moyens d'une cha...  14 janvier 2019       5   \n",
       "1  82€ - 246€  (Selon les tarifs moyens d'une cha...  28 octobre 2018       5   \n",
       "\n",
       "                                              review review_language  \\\n",
       "0  c\\'est le troisi\\u00e8me center parc qu\\'on vi...              fr   \n",
       "1  Seconde fois que nous venons au Center Parcs d...              fr   \n",
       "\n",
       "                      reviewer_id                              title  \\\n",
       "0  <div>Sightsee26280840290</div>  logement tout equip\\u00e9, luxury   \n",
       "1             <div>Kathys25</div>                    D\\u00e9paysant!   \n",
       "\n",
       "         trip_date            trip_type  \n",
       "0     janvier 2019                 None  \n",
       "1   septembre 2018  A voyagé en famille  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjson = pd.read_json('tripadvisor.json')\n",
    "#Previewing DF\n",
    "dfjson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 11 columns):\n",
      "hotel_name         2 non-null object\n",
      "hotel_type         2 non-null object\n",
      "price_range        2 non-null object\n",
      "published_date     2 non-null object\n",
      "rating             2 non-null int64\n",
      "review             2 non-null object\n",
      "review_language    2 non-null object\n",
      "reviewer_id        2 non-null object\n",
      "title              2 non-null object\n",
      "trip_date          2 non-null object\n",
      "trip_type          1 non-null object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dfjson.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
