{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Science for Business - Data Science Consulting - Session 2 \n",
    "\n",
    "# Notebook 1: \n",
    "\n",
    "# Introduction to Web Scraping with Scrapy\n",
    "\n",
    "This notebook aims at explaining the basics of scraping a website using the Python package Scrapy. <br> \n",
    " <br>\n",
    "Useful ressources: <br>\n",
    "-The officiel tutorial: https://docs.scrapy.org/en/latest/intro/tutorial.html <br>\n",
    "-Tutorial to use Scrapy within a Jupyter Notebook: https://www.jitsejan.com/using-scrapy-in-jupyter-notebook.html <br>\n",
    " <br>\n",
    "\n",
    "**To Do**: Run all the cells, and prepare a short explanation of what the Scrapy code is doing in the 3rd part, \"Our first spider\". Don't spend time looking at the other parts today, since these are mainly scripts to use Scrapy inside a Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the JSon pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSon pipeline, you can rename the \"trustpilot.jl\" to the name of your choice\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('trustpilot.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Our first spider \n",
    "\n",
    "Scrapy uses spiders that crawl through the web to get what we want as data. A spider is a piece of code allowing to define the websites we want to scrape, as well as defining the elements you want such as titles, author, content, images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a class with the name of our Spider\n",
    "class TrustSpider(scrapy.Spider):\n",
    "    name = \"trust\"\n",
    "    #Adding URLs to scrap \n",
    "    start_urls = [\n",
    "        'https://fr.trustpilot.com/review/www.centerparcs.fr/fr-fr',\n",
    "    ]\n",
    "    #Custom settings to modify settings usually found in the settings.py file \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'trustpilot.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    #The following function parses the web pages to get the elements \n",
    "    #This is the main function we want you to understand\n",
    "    def parse(self, response):\n",
    "        stars = 'article.review section.review__content div.review-content div.review-content__header div.review-content-header'\n",
    "        date = 'article.review section.review__content div.review-content div.review-content__header div.review-content-header__dates script::text'\n",
    "        for review in response.css('article.review'):\n",
    "            nb_stars = review.css(stars).extract_first()[77] if review.css(stars).extract_first() is not None else -1\n",
    "            pub_date = review.css(date).extract_first()[19:38] if review.css(stars).extract_first() is not None else -1\n",
    "            yield {\n",
    "                'title': review.css('a.link.link--large.link--dark::text').extract_first(),\n",
    "                'content': review.css('p.review-content__text::text').extract_first(),\n",
    "                'author': review.css('div.consumer-information__name::text').extract_first(),\n",
    "                'date': pub_date,\n",
    "                'stars': nb_stars,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crawling\n",
    "\n",
    "The following code is used to launch the crawling of the spider. <br> \n",
    "**Warning**: You can execute the process only once and for one spider per notebook. If you want to relaunch the process, you have to \"Restart and run all\", otherwise you will get an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-14 18:50:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2019-01-14 18:50:51 [scrapy.utils.log] INFO: Versions: lxml 4.3.0.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.2 (default, Jan  2 2019, 17:07:39) [MSC v.1915 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.16299-SP0\n",
      "2019-01-14 18:50:51 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'trustpilot.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(TrustSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading data into Pandas' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Cor Boonen\\n</td>\n",
       "      <td>\\n            Nous avons passé un excellent we...</td>\n",
       "      <td>2018-11-22 17:23:07</td>\n",
       "      <td>4</td>\n",
       "      <td>Week-end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Alain \\n</td>\n",
       "      <td>\\n            Parc très agréable, difficile de...</td>\n",
       "      <td>2018-08-08 07:52:09</td>\n",
       "      <td>3</td>\n",
       "      <td>Les TROIS FORETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n            Manuele Civico\\n</td>\n",
       "      <td>\\n            Pas grand chose ne marche, ni l’...</td>\n",
       "      <td>2018-05-12 10:02:58</td>\n",
       "      <td>1</td>\n",
       "      <td>Pas grand chose ne marche !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n            Sophie Duhamel\\n</td>\n",
       "      <td>\\n            Moi je vais parler aujourd'hui  ...</td>\n",
       "      <td>2017-09-15 11:17:50</td>\n",
       "      <td>1</td>\n",
       "      <td>Non professionnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n            jerome\\n</td>\n",
       "      <td>\\n            calme, reposant, confortable, dé...</td>\n",
       "      <td>2016-10-11 07:54:28</td>\n",
       "      <td>5</td>\n",
       "      <td>bon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   author  \\\n",
       "0      \\n            Cor Boonen\\n           \n",
       "1          \\n            Alain \\n           \n",
       "2  \\n            Manuele Civico\\n           \n",
       "3  \\n            Sophie Duhamel\\n           \n",
       "4          \\n            jerome\\n           \n",
       "\n",
       "                                             content                date  \\\n",
       "0  \\n            Nous avons passé un excellent we... 2018-11-22 17:23:07   \n",
       "1  \\n            Parc très agréable, difficile de... 2018-08-08 07:52:09   \n",
       "2  \\n            Pas grand chose ne marche, ni l’... 2018-05-12 10:02:58   \n",
       "3  \\n            Moi je vais parler aujourd'hui  ... 2017-09-15 11:17:50   \n",
       "4  \\n            calme, reposant, confortable, dé... 2016-10-11 07:54:28   \n",
       "\n",
       "   stars                        title  \n",
       "0      4                     Week-end  \n",
       "1      3             Les TROIS FORETS  \n",
       "2      1  Pas grand chose ne marche !  \n",
       "3      1            Non professionnel  \n",
       "4      5                   bon séjour  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjson = pd.read_json('trustpilot.json')\n",
    "#Preview of the dataframe\n",
    "dfjson.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
